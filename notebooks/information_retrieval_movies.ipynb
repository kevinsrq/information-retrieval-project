{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Documentos\n",
    "\n",
    "A limpeza dos dados é um processo essencial para garantir a qualidade e a confiabilidade das informações armazenadas em um banco de dados. A limpeza dos dados envolve a identificação e a correção de erros, inconsistências, duplicidades e valores ausentes nos dados. A arquitetura do armazenamento é a forma como os dados são organizados, estruturados e acessados em um banco de dados. Uma das opções de arquitetura é o formato YAML, que significa YAML Ain't Markup Language. O YAML é um formato de serialização de dados que usa uma sintaxe simples e legível para representar estruturas de dados como listas, mapas, sequências e escalares. O YAML é compatível com diversas linguagens de programação e pode ser usado para armazenar dados de forma hierárquica e flexível.\n",
    "\n",
    "<!-- <hr style=\"border-width: 1px\" width=\"95%\" > -->\n",
    "<div></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os módulos necessários\n",
    "import os    # Módulo para lidar com funções do sistema operacional\n",
    "import gc    # Módulo para realizar coleta de lixo e gerenciamento de memória\n",
    "import sys\n",
    "\n",
    "import numpy as np   # Módulo para trabalhar com matrizes e funções matemáticas\n",
    "import pandas as pd  # Módulo para trabalhar com dataframes e séries em Python\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div></div> \n",
    "\n",
    "## Estruturação dos Arquivos\n",
    "\n",
    "<div></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney = pd.read_csv('../data/movies/disney_titles.csv')\n",
    "prime = pd.read_csv('../data/movies/prime_titles.csv')\n",
    "hbo = pd.read_csv('../data/movies/hbo_titles.csv')\n",
    "netflix = pd.read_csv('../data/movies/netflix_titles.csv')\n",
    "\n",
    "disney['provider'] = 'disney'\n",
    "prime['provider'] = 'prime'\n",
    "hbo['provider'] = 'hbo'\n",
    "netflix['provider'] = 'netflix'\n",
    "\n",
    "base = pd.concat([disney, prime, hbo, netflix])\n",
    "\n",
    "del disney, prime, hbo, netflix\n",
    "\n",
    "base.dropna(ignore_index=True, inplace=True)\n",
    "base.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div></div> \n",
    "\n",
    "## Processamento de Texto\n",
    "\n",
    "<div></div> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos gêneros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "base['genres'] = base['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Transformação de minúsculos\n",
    "\n",
    "<div></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\\[a-z]): para encontrar todos os caracteres que começam com uma barra invertida () seguida por uma letra minúscula (a-z);\n",
    "# ([^\\w\\]): para encontrar todos os caracteres que não são letras, números ou barras invertidas ();\n",
    "# (\\S+\\d\\S+): para encontrar todos os trechos de texto que contêm um ou mais caracteres não brancos (\\S), \n",
    "# seguidos por um dígito (\\d), seguidos por mais um ou mais caracteres não brancos (\\S).\n",
    "base['post'] = base['description'].replace(r'(\\\\[a-z])|([^\\w\\\\])|(\\S+\\d\\S+)', ' ', regex=True)\n",
    "\n",
    "# Aplicando as funções str.lower() e str.strip() simultaneamente\n",
    "base['post'] = base['post'].apply(lambda x: x.lower().strip() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div></div> \n",
    "\n",
    "### Tokenização e Lemmatizer\n",
    "\n",
    "<div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir.preprocessing import lemmatize_word\n",
    "\n",
    "base['post'] = base['post'].apply(lambda x: ' '.join([lemmatize_word(word.lower()) for word in x.split()]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação das query / docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rand = np.random.random(base.shape[0])\n",
    "\n",
    "d_index = rand <  0.7\n",
    "q_index = rand >= 0.7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir.tf_idf import tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tfidf(base, 'post').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranqueamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_index = base[q_index].index\n",
    "d_index = base[d_index].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_geral = linear_kernel(weights.iloc[d_index], weights.iloc[q_index])\n",
    "rank_geral = pd.DataFrame(rank_geral, index=d_index, columns=q_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3093/3093 - Doc: 1730/3092"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numba\n",
    "\n",
    "def calcular_resultados_relevantes(q_index: list, base: pd.DataFrame) -> 'resultados_relevantes[dict], resultados_sistema[dict]':\n",
    "    resultados_sistema = {}\n",
    "\n",
    "    for q in q_index: \n",
    "        resultados_sistema[q] = rank_geral[q].sort_values(ascending=False).index\n",
    "\n",
    "    resultados_relevantes = {}\n",
    "\n",
    "    for q in q_index:\n",
    "        q_genre = base.iloc[q]['genres']\n",
    "\n",
    "        k = []\n",
    "\n",
    "        for d in resultados_sistema[q]:\n",
    "            d_genre = base.iloc[d]['genres']\n",
    "            \n",
    "            # Verifica qual lista de gêneros é menor para otimizar a comparação\n",
    "            if len(d_genre) > len(q_genre):\n",
    "                comparativo_menor = q_genre\n",
    "                comparativo_maior = d_genre\n",
    "            else:\n",
    "                comparativo_menor = d_genre\n",
    "                comparativo_maior = q_genre\n",
    "            \n",
    "            # Verifica se há pelo menos um gênero em comum entre as listas\n",
    "            partial_relevance = any(i in comparativo_maior for i in comparativo_menor)\n",
    "            \n",
    "            if partial_relevance:\n",
    "                k.append(d)\n",
    "        \n",
    "        print(f'\\rQuery: {q}/{q_index.max()} - Doc: {d}/{d_index.max()}', end='')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        resultados_relevantes[q] = k\n",
    "        \n",
    "    return resultados_relevantes, resultados_sistema\n",
    "\n",
    "resultados_relevantes, resultados_sistema = calcular_resultados_relevantes(q_index, base)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do P@: 0.719268030139934\n"
     ]
    }
   ],
   "source": [
    "def calcular_p_n_media(resultados_relevantes, resultados_sistema, n):\n",
    "    def calcular_p_n(resultados, relevantes):\n",
    "        if len(resultados) > n:\n",
    "            resultados = resultados[:n]  # Considerar apenas os primeiros n resultados\n",
    "        num_relevantes = len(set(resultados) & set(relevantes))  # Contar quantos resultados relevantes foram encontrados\n",
    "        p_n = num_relevantes / n  # Calcular a precisão P@n\n",
    "        return p_n\n",
    "\n",
    "    p_n_total = 0\n",
    "    for consulta, relevantes in resultados_relevantes.items():\n",
    "        resultados = resultados_sistema.get(consulta, [])  # Obtém os resultados retornados pelo sistema para a consulta\n",
    "        p_n = calcular_p_n(resultados, relevantes)\n",
    "        p_n_total += p_n\n",
    "\n",
    "    p_n_media = p_n_total / len(resultados_relevantes)\n",
    "    return p_n_media\n",
    "\n",
    "# Utilizando a função para calcular a média do P@n\n",
    "p_n_media = calcular_p_n_media(resultados_relevantes, resultados_sistema, n=10)\n",
    "print(f\"Média do P@: {p_n_media}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do P@10: 0.719268030139934\n",
      "Média do P@20: 0.6967168998923577\n",
      "Média do P@50: 0.6745748116254034\n",
      "Média do P@100: 0.658902045209902\n"
     ]
    }
   ],
   "source": [
    "for x in [10, 20, 50, 100]: \n",
    "    print(f\"Média do P@{x}: {calcular_p_n_media(resultados_relevantes, resultados_sistema, n=x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5882758350175267"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_precision(relevantes, recomendados):\n",
    "    relevancia_cumulativa = 0\n",
    "    precision_cumulativa = 0\n",
    "    num_relevantes = len(relevantes)\n",
    "    ap = 0\n",
    "\n",
    "    for i, rec in enumerate(recomendados):\n",
    "        if rec in relevantes:\n",
    "            relevancia_cumulativa += 1\n",
    "            precision_cumulativa += relevancia_cumulativa / (i + 1)\n",
    "\n",
    "    if num_relevantes > 0:\n",
    "        ap = precision_cumulativa / num_relevantes\n",
    "\n",
    "    return ap\n",
    "\n",
    "def mean_average_precision(resultados_relevantes, resultados_sistema):\n",
    "    map = 0\n",
    "    num_consultas = len(resultados_relevantes)\n",
    "\n",
    "    for q in resultados_relevantes:\n",
    "        relevantes = resultados_relevantes[q]\n",
    "        recomendados = resultados_sistema[q]\n",
    "        ap = average_precision(relevantes, recomendados)\n",
    "        map += ap\n",
    "\n",
    "    if num_consultas > 0:\n",
    "        map /= num_consultas\n",
    "\n",
    "    return map\n",
    "\n",
    "# Aplicar o MAP nas consultas\n",
    "map_result = mean_average_precision(resultados_relevantes, resultados_sistema)\n",
    "map_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
