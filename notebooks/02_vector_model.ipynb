{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Vetorial para Recuperação da Informação\n",
    "\n",
    "O modelo vetorial é um dos métodos mais utilizados para recuperação de informação, que consiste em representar documentos e consultas como vetores em um espaço multidimensional. Cada dimensão corresponde a um termo do vocabulário da coleção de documentos, e o peso de cada termo é calculado com base na sua frequência e relevância. A recuperação de informação é feita comparando a similaridade entre os vetores de documentos e consultas, usando medidas como o produto escalar ou o cosseno do ângulo entre eles. O modelo vetorial permite recuperar documentos que satisfaçam parcialmente a consulta, definindo um limiar de similaridade mínimo aceitável.\n",
    "\n",
    "<!-- <hr style=\"border-width: 1px\" width=\"95%\" > -->\n",
    "<div></div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os módulos necessários\n",
    "import numpy as np   # Módulo para trabalhar com matrizes e funções matemáticas\n",
    "import pandas as pd  # Módulo para trabalhar com dataframes e séries em Python\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carregue os documentos em uma lista, onde cada documento é uma string.\n",
    "- Instancie o objeto CountVectorizer para transformar o texto em uma matriz de termos.\n",
    "- Ajuste e transforme a matriz de termos usando os dados do conjunto de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_parquet('../data/processed/base_processed.parquet.gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcule a similaridade entre as consultas e os documentos:\n",
    "- Transforme a consulta em uma matriz de termos.\n",
    "- Calcule a similaridade entre a matriz de termos da consulta e a matriz de termos dos documentos usando a função cosine_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancie o objeto CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transforme os documentos em uma matriz de termos\n",
    "term_matrix = vectorizer.fit_transform(database['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/emails/mini_newsgroups/alt.atheism/51126', 'r') as file: \n",
    "    query = file.read()\n",
    "\n",
    "# Transforme a consulta em uma matriz de termos\n",
    "query_vec = vectorizer.transform([query])\n",
    "\n",
    "# Calcule a similaridade entre a consulta e os documentos\n",
    "similarity_scores = cosine_similarity(query_vec, term_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupere os documentos mais relevantes:\n",
    "- Classifique os documentos com base em suas pontuações de similaridade.\n",
    "- Recupere os documentos mais relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53761  - Score: 0.7457440977032672\n",
      "53194  - Score: 0.7438271604938276\n",
      "51126  - Score: 0.7377253439645206\n",
      "51273  - Score: 0.7142800526817401\n",
      "53142  - Score: 0.7017401753421795\n",
      "51160  - Score: 0.7001157311738098\n",
      "54283  - Score: 0.6967342757044788\n",
      "53175  - Score: 0.6939201375033768\n",
      "53172  - Score: 0.6869464497590783\n",
      "53143  - Score: 0.6855706297881646\n",
      "39619  - Score: 0.660578259075816\n",
      "53763  - Score: 0.6472975596607513\n",
      "53144  - Score: 0.6401055804697865\n",
      "101656  - Score: 0.6390178833325828\n",
      "53762  - Score: 0.638752210144836\n",
      "178451  - Score: 0.6386838743880491\n",
      "178846  - Score: 0.6361329120147892\n",
      "83796  - Score: 0.6361329120147892\n",
      "105113  - Score: 0.6293008682666752\n",
      "54241  - Score: 0.6264456087861376\n"
     ]
    }
   ],
   "source": [
    "# Classifique os documentos com base em suas pontuações de similaridade\n",
    "ranked_docs = sorted(\n",
    "    list(enumerate(similarity_scores[0])),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Recupere os documentos mais relevantes\n",
    "for i, score in ranked_docs[0:20]:\n",
    "    print(database.iloc[i]['filename'], \" - Score:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
